\documentclass{article}
\usepackage{fullpage}
\usepackage[utf8x]{inputenc}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{autonum}
\usepackage{dsfont}
\usepackage{stmaryrd}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{remark}{Remark}
\newtheorem{corollary}{Corollary}


\def\1{{\mathds 1}}
\def\G{{\cal G}}
\def\C{{\cal C}}
\def\V{{\cal V}}
\def\Ent{\mathbb N}
\def\R{\mathbb R}
\def\N{\mathfrak N}
\def\M{\mathfrak M}
\def\greed{\mathfrak G}
\newcommand{\suc}[1]{f(#1)}

\def\={\stackrel{def}{=}}
\newcommand{\intset}[1]{\llbracket #1 \rrbracket}
\newcommand{\intpart}[1]{\lceil #1 \rceil}

\begin{document}

\noindent Bruno Scherrer, bruno.scherrer@inria.fr, \today.

~\\

Consider a parity game $G$ between ADAM (or Player 0) and EVE (or Player 1) on a state space $X=\{1,\dots,n\}$ with priority function $\Omega:X \to \{1,\dots,d\}$. On infinite plays, ADAM wants that among the priorities that appears infinitely often, the maximal one is odd, while EVE wants it to be even.

I describe below a procedure that allows to identify a region of the state space that is won by one of the players. Removing the attractor set of this set for this player, and calling it repetitively allows to solve the whole problem.

~\\

Suppose for concreteness that we have a game $G$ of which the maximal priority $p$ is even (the odd case is similar).
Consider the payoff function
\begin{align}
  \forall x,~~ g(x) = \1_{\Omega(x)=p},
\end{align}
and the Bellman operators associated to the corresponding payoff problem: for all $v \in \R^X$,
\begin{align}
  T_{\mu,\nu} v &= g + P_{\mu,\nu}v, \\
  T_{\mu} v & = \min_\nu T_{\mu,\nu} v, \\
  \tilde T_{\nu} v & = \max_\mu T_{\mu,\nu} v, \\
   T v &= \max_\mu \min_\nu T_{\mu,\nu}v = \max_\mu T_\mu v = \min_\nu \tilde T_\nu v,
\end{align}
where $P_{\mu,\nu}$ is the deterministic transition matrix when players use the (positional) strategies $\mu$ and $\nu$.
Let us solve the $n$-horizon problem, by computing
$$
v=T^n 0
$$
and identifying a set of policies $\mu_1,\dots,\mu_n$ and $\nu_1,\dots,\nu_n$ such that
$$
v = T_{\mu_1,\nu_1} \dots T_{\mu_n,\nu_n} 0.
$$
We have the following observation:
\begin{lemma}
  In the parity game $G$, the set of states from which EVE can force ADAM to \emph{only} visit states with priorities lower than $p$ is
  A = \{ x ~;~ v(x)=0 \}.
\end{lemma}
\begin{proof}
  First (the easier part), assume that for some state $x$, EVE has a strategy $\nu$ such that whatever ADAM does, the trajectory only visits states with priorities smaller than $p$. Then, in the $n$-horizon payoff game, this strategy only visit states with payoff $0$, and 
  \begin{align}
   0 \le v(x) =  [T^n0](x) \le [(\tilde T_{\nu})^n 0](x) \le 0.
  \end{align}

  Now, assume that we have a state $x$ such that $v(x)=0$. Against any (positional) strategy $\mu$ of ADAM, consider the trajectory $(x_0=x,x_1,\dots,x_n)$ induced if EVE plays with $\nu_1,\dots,\nu_n$. There necessarily exists $0 \le i<j\le n$ and a state $y \in X$ such that $x_i=x_j=y$. We have
  \begin{align}
    [T_{\mu,\nu_1} \dots T_{\mu,\nu_{i-1}} T_{\mu,\nu_i} \dots T_{\mu,\nu_{j-1}} T^{n-j}0](x) \le [T^n0](x) = 0.
  \end{align}
  Since all the payoffs are non-negative, we deduce that
  \begin{align}
    [T^{n-j}0](y)=0, \\
    [T_{\mu,\nu_i} \dots T_{\mu,\nu_{j-1}} 0](y)=0, \\
    [T_{\mu,\nu_1} \dots T_{\mu,\nu_{i-1}} 0](x)=0.
  \end{align}
  Thus, if EVE plays the infinite-horizon policy $\nu_1,\dots,\nu_{i-1}(\nu_i \dots \nu_{j-1})^\infty$ against ADAM playing $\mu$, then the infinite-horizon payoff of this play is $0$. In $G$, this means that from $x$, the priorities visited are all smaller than $p$.
\end{proof}
\begin{corollary}
Let $G'$ be a clone of the game $G$ where all parities smaller than $p$ are changed to $p-1$. In the parity game $G'$, the winning region of EVE is $B = 1-Attr(A)$ (and the winning region of ADAM is $C=X \backslash B$).
\end{corollary}
If the set $C$ (of the above corrolary) is non empty, then we have found a region where ADAM can win with priority $p$.
If $C$ is empty, we know that $A$ is non-empty.
Furthermore, from any state $x \in A$, we know that EVE has a strategy such that ADAM will never be able to visit a state with priority $p$ (and also that ADAM cannot escape from $A$). We can therefore called recursively this procedure on the game $G$ restricted to $A$ (where the maximal priority is smaller than $p$).

At every call, either one winning region (C) is found, or the maximal priority of the considered game decreases. When there is only one priority, it is necessary a winning region for the corresponding player. In other words this procedure finds a winning region in at most $n$ steps. 





\bibliographystyle{plain}
\bibliography{biblio.bib} 

\end{document}
